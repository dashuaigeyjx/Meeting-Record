## DDPM理解
扩散模型是一种基于能量函数的概率模型，其目的是通过初始状态的蒙特卡洛采样，通过不断更新样本状态，使系统状态分布逐渐接近目标分布。而后科学家又在非均衡热力学的研究中发现，从一个初态经过一系列中间状态最终达到稳定状态，这与扩散模型通过一系列迭代过程从初始状态演化到目标分布的思想相契合。

扩散模型中最重要的思想根基是马尔可夫链，它的一个关键性质是平稳性。即如果一个概率随时间变化，那么在马尔可夫链的作用下，它会趋向于某种平稳分布，时间越长，分布越平稳。如图所示，当你向一滴水中滴入一滴颜料时，无论你滴在什么位置，只要时间足够长，最终颜料都会均匀的分布在水溶液中。这也就是扩散模型的前向过程。

主要分为 Diffusion 和 Reverse 两个阶段。其中 Diffusion 阶段通过不断地对真实图片添加噪声，最终得到一张噪声图片。而 Reverse 阶段，模型需要学习预测出一张噪声图片中的噪声部分，然后减掉该噪声部分，即：去噪。随机采样一张完全噪声图片，通过不断地去噪，最终得到一张符合现实世界图片分布的真实图片。以下是两个阶段的具体原理与公式推导。

![img](https://i-blog.csdnimg.cn/blog_migrate/3d7f6d9e32b5e036d7c337d42ab7a6cb.png#pic_center)


### Diffusion 阶段
这个阶段就是不断地给真实图片加噪声，经过T 步加噪之后，噪声强度不断变大，得到一张完全为噪声的图像。整个扩散过程可以近似看成一次加噪即变为噪声图，那么其实我们只需要搞清楚其中一步加噪就可以了

![img](https://i-blog.csdnimg.cn/blog_migrate/169477fc3791b3f14a862b1de5b1699d.jpeg#pic_center)

*f*(*x*)在论文的公式中有明确的定义：![image-20250330145324196](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20250330145324196.png)

t 是时间序列中一个值，取值范围为 [0,T]，*Zt*是对应时间产生的随机噪声，*βt*是超参数，也是序列中的一个值，在论文的实验部分，其经验值范围是 [10−4,0.02] 线性变化，而且一般来说，t 越大，*βt*的取值也就越大（一开始，加一点点噪声就能比较明显的看出和原图的区别，越到后面，图像退化的越厉害，轻微的扰动已经看不出明显的变化，所以*βt*的值需要更大）

训练时，这样逐步加噪声效率太低了。想要提高训练效率。那么既然最终都会扩散成一个稳定的状态，那么是否我们可以实现从*X*0直接扩散成*XT*呢？

答案是可以的，公式解释如下

 [扩散模型公式推导_202503301313_37196.pdf](C:\WeChat Files\wxid_nia5js3z9gh222\FileStorage\File\2025-03\扩散模型公式推导_202503301313_37196.pdf) 

diffusion阶段的总结：

核心公式（从\(X_0\)一次扩散到\(X_t\)）：

![image-20250330161707075](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20250330161707075.png)

其中某一步（从\(X_{t - 1}\)扩散到\(X_t\)）：

![image-20250330161724803](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20250330161724803.png)

### Reverse 阶段
我们先来看一下整个 reverse 阶段是在做什么，首先取出 batch size 大小的 t，然后针对每个 image 做 diffusion，将我们得到的 noise 图像放到 UNet 网络预测噪声\(\tilde{Z}\)（指代图中\(Z'\)），然后用 noise 信息预测多余的噪声\(\tilde{Z}\)。

所以整个 ddpm，需要训练的就是一个预测噪声的网络，使得预测出来的噪声与实际加的噪声越接近越好。对比 GAN 网络，不难发现 GAN 是需要训练 2 个模型，训练过程极其不稳定，有时候生成器训好了，判别器却没训好，以至于 loss 都不能真实的反映网络的性能。而 ddpm 只需要训练一个网络，相比之下稳定很多。

![img](https://i-blog.csdnimg.cn/blog_migrate/79421965cc14bb2e703fb560cecef0de.jpeg#pic_center)

在加噪声的过程中，我们为了减少计算消耗，算出了一次扩散的公式，理论上我们也可以得到一次减噪的公式：![image-20250330162024718](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20250330162024718.png)

论文中的结论可以知道，这么做的效果比较差，图片是很模糊的，不符合逆扩散的过程，最好还是一步一步推。先根据\(X_t\)预测出\(\tilde{Z}\)，求出\(X_{t - 1}\)，然后逐步逐步得到\(X_0\)，这个过程如下图所示：

![img](https://i-blog.csdnimg.cn/blog_migrate/3eb0715034bc7af28b1259a7556d62ad.jpeg#pic_center)

最终得到的公式就长这样

![image-20250330194046771](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20250330194046771.png)

### 最后

训练过程中，我们对每个x都会采样出一个t，然后根据t，生成对应的噪声（\epsilon\），我们的 UNet 网络需要预测的就是这个噪声，它的参数被记作\(\theta\)，这里额外说明一下，也并不是一定要用 UNet，只是这个网络结构资源消耗和适用性更好。当训练完成之后，我们就有了一个去噪网络。

采样过程中，我们是没有任何真实图像的，所以我们需要从一个标准正态分布中采样一个\(X_T\)，这是我们采样的起点，接下来，我们会对它做T步的 reverse，一直推到\(X_0\)，这里算法还有个小细节，只有\(t > 1\)的时候，z才需要采样，否则它就是 0，当\(t = 0\)时，我们想求的就是真实的\(X_0\)，这时候就不需要加扰动了，它必须是个确定的结果。相当于均值给定的是一个确定的生成方向，方差和噪声给定的是一个不确定的方向。另外呢，从训练经验来看，这个扰动值也不需要和推理结果完全一样，论文只是提供了这个扰动强度的上界\(\sigma\)，比他小甚至为 0，也是可以的。
